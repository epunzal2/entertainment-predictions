{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From all the movies listed on nextbestpicture.com for the Oscars, get their ratings on Metacritic, Rotten Tomatoes, Letterboxd, and IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "pd.set_option('display.max_columns', None) # we want to display all columns in this notebook\n",
    "pd.set_option('display.max_rows', 100) # increase number of displayed rows\n",
    "\n",
    "# random seed\n",
    "my_random_seed = 123\n",
    "random.seed(128)\n",
    "\n",
    "# aesthetics\n",
    "default_color_1 = 'darkblue'\n",
    "default_color_2 = 'darkgreen'\n",
    "default_color_3 = 'darkred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website is functional\n"
     ]
    }
   ],
   "source": [
    "# url = \"https://letterboxd.tools\"\n",
    "# url = \"https://metacritic.com\"\n",
    "url = \"https://nextbestpicture.com/oscar-predictions/\"\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.5481.78 Safari/537.36',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Connection': 'keep-alive',\n",
    "    'DNT': '1',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Website is functional\")\n",
    "    else:\n",
    "        print(\"Can't access.\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error accessing the website: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oscar Predictions\n",
      "Best Picture\n",
      "Best Director\n",
      "Best Actress\n",
      "Best Actor\n",
      "Best Supporting Actress\n",
      "Best Supporting Actor\n",
      "Best Adapted Screenplay\n",
      "Best Original Screenplay\n",
      "Best Animated Feature\n",
      "Best Documentary Feature\n",
      "Best International Feature\n",
      "Best Cinematography\n",
      "Best Costume Design\n",
      "Best Film Editing\n",
      "Best Makeup and Hairstyling\n",
      "Best Production Design\n",
      "Best Original Score\n",
      "Best Original Song\n",
      "Best Sound\n",
      "Best Visual Effects\n",
      "Best Animated Short Film\n",
      "Best Documentary Short Film\n",
      "Best Live Action Short Film\n"
     ]
    }
   ],
   "source": [
    "# bs4\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    titles = soup.find_all(['h1', 'h2'])\n",
    "    for title in titles:\n",
    "        print(title.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 379 sections on the page.\n"
     ]
    }
   ],
   "source": [
    "sections = soup.find_all('div')  # Broad search to capture all divs\n",
    "print(f\"Found {len(sections)} sections on the page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46 tables on the page.\n"
     ]
    }
   ],
   "source": [
    "tables = soup.find_all('table', attrs={'data-ninja_table_instance': True})\n",
    "print(f\"Found {len(tables)} tables on the page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category: Best Picture\n",
      "\n",
      "Category: Best Director\n",
      "\n",
      "Category: Best Actress\n",
      "\n",
      "Category: Best Actor\n",
      "\n",
      "Category: Best Supporting Actress\n",
      "\n",
      "Category: Best Supporting Actor\n",
      "\n",
      "Category: Best Adapted Screenplay\n",
      "\n",
      "Category: Best Original Screenplay\n",
      "\n",
      "Category: Best Animated Feature\n",
      "\n",
      "Category: Best Documentary Feature\n",
      "\n",
      "Category: Best International Feature\n",
      "\n",
      "Category: Best Cinematography\n",
      "\n",
      "Category: Best Costume Design\n",
      "\n",
      "Category: Best Film Editing\n",
      "\n",
      "Category: Best Makeup and Hairstyling\n",
      "\n",
      "Category: Best Production Design\n",
      "\n",
      "Category: Best Original Score\n",
      "\n",
      "Category: Best Original Song\n",
      "\n",
      "Category: Best Sound\n",
      "\n",
      "Category: Best Visual Effects\n",
      "\n",
      "Category: Best Animated Short Film\n",
      "\n",
      "Category: Best Documentary Short Film\n",
      "\n",
      "Category: Best Live Action Short Film\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Extract data without repeating category titles\n",
    "seen_categories = set()  # To track printed category titles\n",
    "categories_dict = {}\n",
    "\n",
    "for table in tables:\n",
    "    # Get the category title by finding the nearest header\n",
    "    category_title = table.find_previous('h2')\n",
    "    if category_title:\n",
    "        title_text = category_title.get_text(strip=True)\n",
    "        if title_text not in seen_categories:\n",
    "            print(f\"\\nCategory: {title_text}\")\n",
    "            seen_categories.add(title_text)  # Add to the seen set\n",
    "            categories_dict[title_text] = {}\n",
    "\n",
    "    # # Extract rows from the table\n",
    "    # rows = table.find_all('tr')[1:]  # Skip the header row\n",
    "    # for i, row in enumerate(rows):\n",
    "    #     columns = row.find_all('td')\n",
    "    #     if len(columns) >= 2:  # Ensure there are at least Rank and Picture columns\n",
    "    #         rank = columns[0].get_text(strip=True)\n",
    "    #         picture = columns[1].get_text(strip=True) # entry\n",
    "    #         categories_dict[ftitle_text][rank] = picture\n",
    "    #         print(f\"  Rank: {rank}, Picture: {picture}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entertainment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
